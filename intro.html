<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 What Is This Book About? | The Pragmatic Programmer for Machine Learning</title>
  <meta name="description" content="…" />
  <meta name="generator" content="bookdown 0.27 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 What Is This Book About? | The Pragmatic Programmer for Machine Learning" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="…" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 What Is This Book About? | The Pragmatic Programmer for Machine Learning" />
  
  <meta name="twitter:description" content="…" />
  

<meta name="author" content="Marco Scutari, Mauro Malvestio" />


<meta name="date" content="2023-04-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="hardware.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script type="text/javascript">
    (function(c,l,a,r,i,t,y){
        c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
        t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
        y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
    })(window, document, "clarity", "script", "glf74rs5fz");
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> What Is This Book About?</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#intro-ml"><i class="fa fa-check"></i><b>1.1</b> Machine Learning</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#intro-ds"><i class="fa fa-check"></i><b>1.2</b> Data Science</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#intro-sweng"><i class="fa fa-check"></i><b>1.3</b> Software Engineering</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#intro-together"><i class="fa fa-check"></i><b>1.4</b> How Do They Go Together?</a></li>
</ul></li>
<li class="part"><span><b>I Foundations of Scientific Computing</b></span></li>
<li class="chapter" data-level="2" data-path="hardware.html"><a href="hardware.html"><i class="fa fa-check"></i><b>2</b> Hardware Architectures</a>
<ul>
<li class="chapter" data-level="2.1" data-path="hardware.html"><a href="hardware.html#hardware-types"><i class="fa fa-check"></i><b>2.1</b> Types of Hardware</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="hardware.html"><a href="hardware.html#hardware-compute"><i class="fa fa-check"></i><b>2.1.1</b> Compute</a></li>
<li class="chapter" data-level="2.1.2" data-path="hardware.html"><a href="hardware.html#hardware-memory"><i class="fa fa-check"></i><b>2.1.2</b> Memory</a></li>
<li class="chapter" data-level="2.1.3" data-path="hardware.html"><a href="hardware.html#hardware-connections"><i class="fa fa-check"></i><b>2.1.3</b> Connections</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="hardware.html"><a href="hardware.html#hardware-using"><i class="fa fa-check"></i><b>2.2</b> Making Hardware Live Up to Expectations</a></li>
<li class="chapter" data-level="2.3" data-path="hardware.html"><a href="hardware.html#hardware-cloud"><i class="fa fa-check"></i><b>2.3</b> Local and Remote Hardware</a></li>
<li class="chapter" data-level="2.4" data-path="hardware.html"><a href="hardware.html#hardware-choice"><i class="fa fa-check"></i><b>2.4</b> Choosing the Right Hardware for the Job</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="types-structures.html"><a href="types-structures.html"><i class="fa fa-check"></i><b>3</b> Variable Types and Data Structures</a>
<ul>
<li class="chapter" data-level="3.1" data-path="types-structures.html"><a href="types-structures.html#variable-types"><i class="fa fa-check"></i><b>3.1</b> Variable Types</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="types-structures.html"><a href="types-structures.html#integers"><i class="fa fa-check"></i><b>3.1.1</b> Integers</a></li>
<li class="chapter" data-level="3.1.2" data-path="types-structures.html"><a href="types-structures.html#floating-point"><i class="fa fa-check"></i><b>3.1.2</b> Floating Point</a></li>
<li class="chapter" data-level="3.1.3" data-path="types-structures.html"><a href="types-structures.html#string-types"><i class="fa fa-check"></i><b>3.1.3</b> Strings</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="types-structures.html"><a href="types-structures.html#data-structures"><i class="fa fa-check"></i><b>3.2</b> Data Structures</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="types-structures.html"><a href="types-structures.html#vectors-lists"><i class="fa fa-check"></i><b>3.2.1</b> Vectors and Lists</a></li>
<li class="chapter" data-level="3.2.2" data-path="types-structures.html"><a href="types-structures.html#dataframes"><i class="fa fa-check"></i><b>3.2.2</b> Representing Data with Data Frames</a></li>
<li class="chapter" data-level="3.2.3" data-path="types-structures.html"><a href="types-structures.html#matrices"><i class="fa fa-check"></i><b>3.2.3</b> Dense and Sparse Matrices</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="types-structures.html"><a href="types-structures.html#right-variables"><i class="fa fa-check"></i><b>3.3</b> Choosing the Right Variable Types for the Job</a></li>
<li class="chapter" data-level="3.4" data-path="types-structures.html"><a href="types-structures.html#right-data-structures"><i class="fa fa-check"></i><b>3.4</b> Choosing the Right Data Structures for the Job</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="algorithms.html"><a href="algorithms.html"><i class="fa fa-check"></i><b>4</b> Analysis of Algorithms</a>
<ul>
<li class="chapter" data-level="4.1" data-path="algorithms.html"><a href="algorithms.html#pseudocode"><i class="fa fa-check"></i><b>4.1</b> Writing Pseudocode</a></li>
<li class="chapter" data-level="4.2" data-path="algorithms.html"><a href="algorithms.html#bigO-intro"><i class="fa fa-check"></i><b>4.2</b> Computational Complexity and Big-<span class="math inline">\(O\)</span> Notation</a></li>
<li class="chapter" data-level="4.3" data-path="algorithms.html"><a href="algorithms.html#bigO-benchmark"><i class="fa fa-check"></i><b>4.3</b> Big-<span class="math inline">\(O\)</span> Notation and Benchmarking</a></li>
<li class="chapter" data-level="4.4" data-path="algorithms.html"><a href="algorithms.html#bigO-ml"><i class="fa fa-check"></i><b>4.4</b> Algorithm Analysis for Machine Learning</a></li>
<li class="chapter" data-level="4.5" data-path="algorithms.html"><a href="algorithms.html#bigO-examples"><i class="fa fa-check"></i><b>4.5</b> Some Examples of Algorithm Analysis</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="algorithms.html"><a href="algorithms.html#bigO-lm"><i class="fa fa-check"></i><b>4.5.1</b> Estimating Linear Regression Models</a></li>
<li class="chapter" data-level="4.5.2" data-path="algorithms.html"><a href="algorithms.html#bigO-sparsem"><i class="fa fa-check"></i><b>4.5.2</b> Sparse Matrices Representation</a></li>
<li class="chapter" data-level="4.5.3" data-path="algorithms.html"><a href="algorithms.html#bigO-dags"><i class="fa fa-check"></i><b>4.5.3</b> Uniform Simulations of Directed Acyclic Graphs</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="algorithms.html"><a href="algorithms.html#bigO-performance"><i class="fa fa-check"></i><b>4.6</b> Big-<span class="math inline">\(O\)</span> Notation and Real-World Performance</a></li>
</ul></li>
<li class="part"><span><b>II Best Practices for Machine Learning Pipelines</b></span></li>
<li class="chapter" data-level="5" data-path="design-code.html"><a href="design-code.html"><i class="fa fa-check"></i><b>5</b> Designing and Structuring Pipelines</a>
<ul>
<li class="chapter" data-level="5.1" data-path="design-code.html"><a href="design-code.html#data-as-code"><i class="fa fa-check"></i><b>5.1</b> Data as Code</a></li>
<li class="chapter" data-level="5.2" data-path="design-code.html"><a href="design-code.html#technical-debt"><i class="fa fa-check"></i><b>5.2</b> Technical Debt</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="design-code.html"><a href="design-code.html#data-debt"><i class="fa fa-check"></i><b>5.2.1</b> At the Data Level</a></li>
<li class="chapter" data-level="5.2.2" data-path="design-code.html"><a href="design-code.html#model-debt"><i class="fa fa-check"></i><b>5.2.2</b> At the Model Level</a></li>
<li class="chapter" data-level="5.2.3" data-path="design-code.html"><a href="design-code.html#architecture-debt"><i class="fa fa-check"></i><b>5.2.3</b> At the Architecture (Design) Level</a></li>
<li class="chapter" data-level="5.2.4" data-path="design-code.html"><a href="design-code.html#code-debt"><i class="fa fa-check"></i><b>5.2.4</b> At the Code Level</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="design-code.html"><a href="design-code.html#processing-pipeline"><i class="fa fa-check"></i><b>5.3</b> Machine Learning Pipeline</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="design-code.html"><a href="design-code.html#scoping-pipeline"><i class="fa fa-check"></i><b>5.3.1</b> Project Scoping</a></li>
<li class="chapter" data-level="5.3.2" data-path="design-code.html"><a href="design-code.html#baseline-pipeline"><i class="fa fa-check"></i><b>5.3.2</b> Producing a Baseline Implementation</a></li>
<li class="chapter" data-level="5.3.3" data-path="design-code.html"><a href="design-code.html#data-pipeline"><i class="fa fa-check"></i><b>5.3.3</b> Data Ingestion and Preparation</a></li>
<li class="chapter" data-level="5.3.4" data-path="design-code.html"><a href="design-code.html#model-pipeline"><i class="fa fa-check"></i><b>5.3.4</b> Model Training, Evaluation and Validation</a></li>
<li class="chapter" data-level="5.3.5" data-path="design-code.html"><a href="design-code.html#production-pipeline"><i class="fa fa-check"></i><b>5.3.5</b> Deployment, Serving and Inference</a></li>
<li class="chapter" data-level="5.3.6" data-path="design-code.html"><a href="design-code.html#monitoring-pipeline"><i class="fa fa-check"></i><b>5.3.6</b> Monitoring, Logging and Reporting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="writing-code.html"><a href="writing-code.html"><i class="fa fa-check"></i><b>6</b> Writing Machine Learning Code</a>
<ul>
<li class="chapter" data-level="6.1" data-path="writing-code.html"><a href="writing-code.html#programming-language"><i class="fa fa-check"></i><b>6.1</b> Choosing Languages and Libraries</a></li>
<li class="chapter" data-level="6.2" data-path="writing-code.html"><a href="writing-code.html#naming"><i class="fa fa-check"></i><b>6.2</b> Naming Things</a></li>
<li class="chapter" data-level="6.3" data-path="writing-code.html"><a href="writing-code.html#coding-standards"><i class="fa fa-check"></i><b>6.3</b> Coding Styles and Coding Standards</a></li>
<li class="chapter" data-level="6.4" data-path="writing-code.html"><a href="writing-code.html#filesystem-structure"><i class="fa fa-check"></i><b>6.4</b> Filesystem Structure</a></li>
<li class="chapter" data-level="6.5" data-path="writing-code.html"><a href="writing-code.html#versioning"><i class="fa fa-check"></i><b>6.5</b> Effective Versioning</a></li>
<li class="chapter" data-level="6.6" data-path="writing-code.html"><a href="writing-code.html#code-review"><i class="fa fa-check"></i><b>6.6</b> Code Review</a></li>
<li class="chapter" data-level="6.7" data-path="writing-code.html"><a href="writing-code.html#refactoring"><i class="fa fa-check"></i><b>6.7</b> Refactoring</a></li>
<li class="chapter" data-level="6.8" data-path="writing-code.html"><a href="writing-code.html#reworking"><i class="fa fa-check"></i><b>6.8</b> Reworking Academic Code: An Example</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="deploying-code.html"><a href="deploying-code.html"><i class="fa fa-check"></i><b>7</b> Packaging and Deploying Pipelines</a>
<ul>
<li class="chapter" data-level="7.1" data-path="deploying-code.html"><a href="deploying-code.html#deployment-prep"><i class="fa fa-check"></i><b>7.1</b> Model Packaging</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="deploying-code.html"><a href="deploying-code.html#standalone-packaging"><i class="fa fa-check"></i><b>7.1.1</b> Standalone Packaging</a></li>
<li class="chapter" data-level="7.1.2" data-path="deploying-code.html"><a href="deploying-code.html#distribution-packaging"><i class="fa fa-check"></i><b>7.1.2</b> Programming Language Package Managers</a></li>
<li class="chapter" data-level="7.1.3" data-path="deploying-code.html"><a href="deploying-code.html#vm-packaging"><i class="fa fa-check"></i><b>7.1.3</b> Virtual Machines</a></li>
<li class="chapter" data-level="7.1.4" data-path="deploying-code.html"><a href="deploying-code.html#container-packaging"><i class="fa fa-check"></i><b>7.1.4</b> Containers</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="deploying-code.html"><a href="deploying-code.html#deployment-strategies"><i class="fa fa-check"></i><b>7.2</b> Model Deployment: Strategies</a></li>
<li class="chapter" data-level="7.3" data-path="deploying-code.html"><a href="deploying-code.html#deployment-process"><i class="fa fa-check"></i><b>7.3</b> Model Deployment: Infrastructure</a></li>
<li class="chapter" data-level="7.4" data-path="deploying-code.html"><a href="deploying-code.html#deployment-monitoring"><i class="fa fa-check"></i><b>7.4</b> Model Deployment: Monitoring and Logging</a></li>
<li class="chapter" data-level="7.5" data-path="deploying-code.html"><a href="deploying-code.html#deployment-fails"><i class="fa fa-check"></i><b>7.5</b> What Can Possibly Go Wrong?</a></li>
<li class="chapter" data-level="7.6" data-path="deploying-code.html"><a href="deploying-code.html#rollback"><i class="fa fa-check"></i><b>7.6</b> Rolling Back</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="documenting-code.html"><a href="documenting-code.html"><i class="fa fa-check"></i><b>8</b> Documenting Pipelines</a>
<ul>
<li class="chapter" data-level="8.1" data-path="documenting-code.html"><a href="documenting-code.html#comments"><i class="fa fa-check"></i><b>8.1</b> Comments</a></li>
<li class="chapter" data-level="8.2" data-path="documenting-code.html"><a href="documenting-code.html#apidocs"><i class="fa fa-check"></i><b>8.2</b> Documenting Public Interfaces</a></li>
<li class="chapter" data-level="8.3" data-path="documenting-code.html"><a href="documenting-code.html#designdocs"><i class="fa fa-check"></i><b>8.3</b> Documenting Architecture and Design</a></li>
<li class="chapter" data-level="8.4" data-path="documenting-code.html"><a href="documenting-code.html#domaindocs"><i class="fa fa-check"></i><b>8.4</b> Documenting Algorithms and Business Cases</a></li>
<li class="chapter" data-level="8.5" data-path="documenting-code.html"><a href="documenting-code.html#usecases"><i class="fa fa-check"></i><b>8.5</b> Illustrating Practical Use Cases</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="troubleshooting-code.html"><a href="troubleshooting-code.html"><i class="fa fa-check"></i><b>9</b> Troubleshooting and Testing Pipelines</a>
<ul>
<li class="chapter" data-level="9.1" data-path="troubleshooting-code.html"><a href="troubleshooting-code.html#data-problems"><i class="fa fa-check"></i><b>9.1</b> Data Are the Problem</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="troubleshooting-code.html"><a href="troubleshooting-code.html#troubleshooting-large-data"><i class="fa fa-check"></i><b>9.1.1</b> Large Data</a></li>
<li class="chapter" data-level="9.1.2" data-path="troubleshooting-code.html"><a href="troubleshooting-code.html#troubleshooting-heterogeneous-data"><i class="fa fa-check"></i><b>9.1.2</b> Heterogeneous Data</a></li>
<li class="chapter" data-level="9.1.3" data-path="troubleshooting-code.html"><a href="troubleshooting-code.html#troubleshooting-dynamic-data"><i class="fa fa-check"></i><b>9.1.3</b> Dynamic Data</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="troubleshooting-code.html"><a href="troubleshooting-code.html#model-problems"><i class="fa fa-check"></i><b>9.2</b> Models Are the Problem</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="troubleshooting-code.html"><a href="troubleshooting-code.html#troubleshooting-large-models"><i class="fa fa-check"></i><b>9.2.1</b> Large Models</a></li>
<li class="chapter" data-level="9.2.2" data-path="troubleshooting-code.html"><a href="troubleshooting-code.html#troubleshooting-black-boxes"><i class="fa fa-check"></i><b>9.2.2</b> Black-Box Models</a></li>
<li class="chapter" data-level="9.2.3" data-path="troubleshooting-code.html"><a href="troubleshooting-code.html#troubleshooting-costly-models"><i class="fa fa-check"></i><b>9.2.3</b> Costly Models</a></li>
<li class="chapter" data-level="9.2.4" data-path="troubleshooting-code.html"><a href="troubleshooting-code.html#troubleshooting-pipelines"><i class="fa fa-check"></i><b>9.2.4</b> Many Models</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="troubleshooting-code.html"><a href="troubleshooting-code.html#signs-of-trouble"><i class="fa fa-check"></i><b>9.3</b> Common Signs That Something Is Up</a></li>
<li class="chapter" data-level="9.4" data-path="troubleshooting-code.html"><a href="troubleshooting-code.html#testing"><i class="fa fa-check"></i><b>9.4</b> Tests Are the Solution</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="troubleshooting-code.html"><a href="troubleshooting-code.html#testing-goals"><i class="fa fa-check"></i><b>9.4.1</b> What Do We Want to Achieve?</a></li>
<li class="chapter" data-level="9.4.2" data-path="troubleshooting-code.html"><a href="troubleshooting-code.html#testing-what"><i class="fa fa-check"></i><b>9.4.2</b> What Should We Test?</a></li>
<li class="chapter" data-level="9.4.3" data-path="troubleshooting-code.html"><a href="troubleshooting-code.html#offline-vs-online"><i class="fa fa-check"></i><b>9.4.3</b> Offline and Online Data</a></li>
<li class="chapter" data-level="9.4.4" data-path="troubleshooting-code.html"><a href="troubleshooting-code.html#local-vs-global"><i class="fa fa-check"></i><b>9.4.4</b> Testing Local and Testing Global</a></li>
<li class="chapter" data-level="9.4.5" data-path="troubleshooting-code.html"><a href="troubleshooting-code.html#conceptual-vs-implementation"><i class="fa fa-check"></i><b>9.4.5</b> Conceptual and Implementation Errors</a></li>
<li class="chapter" data-level="9.4.6" data-path="troubleshooting-code.html"><a href="troubleshooting-code.html#test-coverage"><i class="fa fa-check"></i><b>9.4.6</b> Code Coverage and Test Prioritisation</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Tools and Technologies</b></span></li>
<li class="chapter" data-level="10" data-path="development-tools.html"><a href="development-tools.html"><i class="fa fa-check"></i><b>10</b> Tools for Developing Pipelines</a>
<ul>
<li class="chapter" data-level="10.1" data-path="development-tools.html"><a href="development-tools.html#exploration-experiment-tracking"><i class="fa fa-check"></i><b>10.1</b> Data Exploration and Experiment Tracking</a></li>
<li class="chapter" data-level="10.2" data-path="development-tools.html"><a href="development-tools.html#code-development"><i class="fa fa-check"></i><b>10.2</b> Code Development</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="development-tools.html"><a href="development-tools.html#editors"><i class="fa fa-check"></i><b>10.2.1</b> Code Editors and IDEs</a></li>
<li class="chapter" data-level="10.2.2" data-path="development-tools.html"><a href="development-tools.html#notebooks"><i class="fa fa-check"></i><b>10.2.2</b> Notebooks</a></li>
<li class="chapter" data-level="10.2.3" data-path="development-tools.html"><a href="development-tools.html#accessing-documentation"><i class="fa fa-check"></i><b>10.2.3</b> Accessing Data and Documentation</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="development-tools.html"><a href="development-tools.html#build-test-doc-tools"><i class="fa fa-check"></i><b>10.3</b> Build, Test and Documentation Tools</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="production-tools.html"><a href="production-tools.html"><i class="fa fa-check"></i><b>11</b> Tools to Manage Pipelines in Production</a>
<ul>
<li class="chapter" data-level="11.1" data-path="production-tools.html"><a href="production-tools.html#production-infra"><i class="fa fa-check"></i><b>11.1</b> Infrastructure Management</a></li>
<li class="chapter" data-level="11.2" data-path="production-tools.html"><a href="production-tools.html#production-software"><i class="fa fa-check"></i><b>11.2</b> Machine Learning Software Management</a></li>
<li class="chapter" data-level="11.3" data-path="production-tools.html"><a href="production-tools.html#production-dashboard"><i class="fa fa-check"></i><b>11.3</b> Dashboards, Visualisation and Reporting</a></li>
</ul></li>
<li class="part"><span><b>IV A Case Study</b></span></li>
<li class="chapter" data-level="12" data-path="nlp.html"><a href="nlp.html"><i class="fa fa-check"></i><b>12</b> Recommending Recommendations: A Recommender System Using Natural Language Understanding</a>
<ul>
<li class="chapter" data-level="12.1" data-path="nlp.html"><a href="nlp.html#nlp-domain"><i class="fa fa-check"></i><b>12.1</b> The Domain Problem</a></li>
<li class="chapter" data-level="12.2" data-path="nlp.html"><a href="nlp.html#nlp-model"><i class="fa fa-check"></i><b>12.2</b> The Machine Learning Model</a></li>
<li class="chapter" data-level="12.3" data-path="nlp.html"><a href="nlp.html#nlp-infra"><i class="fa fa-check"></i><b>12.3</b> The Infrastructure</a></li>
<li class="chapter" data-level="12.4" data-path="nlp.html"><a href="nlp.html#nlp-architecture"><i class="fa fa-check"></i><b>12.4</b> The Architecture of the Pipeline</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="nlp.html"><a href="nlp.html#nlp-ingestion-preparation"><i class="fa fa-check"></i><b>12.4.1</b> Data Ingestion and Data Preparation</a></li>
<li class="chapter" data-level="12.4.2" data-path="nlp.html"><a href="nlp.html#nlp-tracking-with-dvc"><i class="fa fa-check"></i><b>12.4.2</b> Data Tracking and Versioning</a></li>
<li class="chapter" data-level="12.4.3" data-path="nlp.html"><a href="nlp.html#nlp-training-exp-tracking"><i class="fa fa-check"></i><b>12.4.3</b> Training and Experiment Tracking</a></li>
<li class="chapter" data-level="12.4.4" data-path="nlp.html"><a href="nlp.html#nlp-model-packaging"><i class="fa fa-check"></i><b>12.4.4</b> Model Packaging</a></li>
<li class="chapter" data-level="12.4.5" data-path="nlp.html"><a href="nlp.html#nlp-deployment-inference"><i class="fa fa-check"></i><b>12.4.5</b> Deployment and Inference</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Pragmatic Programmer for Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="intro" class="section level1 hasAnchor" number="1">
<h1><span class="header-section-number">Chapter 1</span> What Is This Book About?<a href="intro.html#intro" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>The modern practice of data analysis is shaped by the convergence of many disciplines, each with its own history:
information theory, computer science, optimisation, probability and statistics among them. Machine learning and data
science can be considered their latest incarnations, inheriting the mantle of what used to be called “data analytics”.
Software engineering should be considered as a crucial addition to this list. Why do we need it to implement
modern data analysis efficiently and effectively?</p>
<div id="intro-ml" class="section level2 hasAnchor" number="1.1">
<h2><span class="header-section-number">1.1</span> Machine Learning<a href="intro.html#intro-ml" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There are many definitions of machine learning. Broadly speaking, it is a discipline that aims to create computer
systems and algorithms that can learn a structured representation of reality without (or with less) human supervision in
order to interact with it <span class="citation">(Russell and Norvig <a href="#ref-norvig" role="doc-biblioref">2009</a>)</span>. At one end of the spectrum, we can take this to be a narrow version of artificial
general intelligence in which we want our computer systems to learn intellectual tasks independently and to generalise
them to new problems, much like a human being would. At the other end, we can view machine learning as the ability to
learn probabilistic models that provide a simplified representation of a specific phenomenon to perform a specific task
<span class="citation">(Ghahramani <a href="#ref-zoubin" role="doc-biblioref">2015</a>)</span> such as predicting an outcome of interest (supervised learning) or finding meaningful patterns in the data
(unsupervised learning). Somewhere in between these two extremes lie expert systems <span class="citation">(Castillo, Gutiérrez, and Hadi <a href="#ref-castillo" role="doc-biblioref">1997</a>)</span>, which “capture the
ability to think and reason about as an expert would in a particular domain” and can provide “a meaningful answer to a
less than fully specified question.”</p>
<p>Broadly speaking, in order to do this:</p>
<ol style="list-style-type: decimal">
<li>We need a working model of the world that describes the task and its context in a way that a computer can understand.</li>
<li>We need a goal: how do we measure the performance of the model? Because that is what we optimise for! Usually, it is
the ability to predict new events.</li>
<li>We encode our knowledge of the world, drawing information from training data, experts or both.</li>
<li>The computer system uses the model as a proxy of reality and, as new inputs come in, to perform inference and decide
if and how to perform the assigned task.</li>
</ol>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:data-vs-modeller"></span>
<img src="chapter01/figures/data-vs-modeller.svg" alt="Different approaches to data analysis grouped by their sources of information: the data or the assumptions made by the modeller." width="80%" />
<p class="caption">
Figure 1.1: Different approaches to data analysis grouped by their sources of information: the data or the assumptions made by the modeller.
</p>
</div>
<p>The exact form these elements take will depend on the domain we are trying to represent and on the model we will use to
represent it. Machine learning is, at its core, a collection of models and algorithms from optimisation, statistics,
probability and information theory that deal with abstract problems: from simple linear regression models <span class="citation">(Weisberg <a href="#ref-weisberg" role="doc-biblioref">2014</a>)</span>,
to Bayesian networks <span class="citation">(Scutari and Denis <a href="#ref-scutari" role="doc-biblioref">2021</a>)</span>, to more complex models such as deep neural networks <span class="citation">(Goodfellow, Bengio, and Courville <a href="#ref-goodfellow" role="doc-biblioref">2016</a>)</span> and Gaussian
processes <span class="citation">(Rasmussen and Williams <a href="#ref-gaussianproc" role="doc-biblioref">2006</a>)</span>. These algorithms can be applied to a variety of domains from healthcare <span class="citation">(van der Schaar et al. <a href="#ref-mihaela" role="doc-biblioref">2021</a>)</span> to natural
language processing <span class="citation">(Aggarwal <a href="#ref-mlfortext" role="doc-biblioref">2018</a>)</span> and computer vision <span class="citation">(Voulodimos et al. <a href="#ref-vision" role="doc-biblioref">2018</a>)</span>, with some combinations of algorithms and domains working
out better than others.</p>
<p>In classical statistics (Figure <a href="intro.html#fig:data-vs-modeller">1.1</a>, bottom right), analysing data required the modeller to
specify the probabilistic model generating them in order to draw inferences from a limited number of data points. Such
models would necessarily have a simple structure for two reasons: because the modeller had to manually interpret their
properties and their output, and because of the lack of any substantial computing power to estimate their parameters.
This approach would put all the burden on the modeller: most of the utility that could be had from the model would come
from the ability of the modeller to distil whatever he was modelling into simple mathematics and to incorporate any
available prior information into the model structure. The result is the emphasis on closed-form results, low-order
approximations and asymptotics that characterises the earlier part of modern statistics.</p>
<p>There are, however, many phenomena that cannot be feasibly studied in this fashion. Firstly, there are limits to a human
modeller’s ability to encode complex behaviour when manually structuring models. These limits can easily be exceeded by
phenomena involving large numbers of variables or by non-linear patterns of interactions between variables that are not
very regular or known in advance. Secondly, there may not be enough information available to even attempt to structure a
probabilistic model. Thirdly, limiting our choice of models to those that can be written in closed form to allow the
modeller to fit, interpret and use them manually, without a significant use of computing power, does not necessarily
ensure that those models are easy to interpret. For instance, there are many documented pitfalls in interpreting
logistic regression <span class="citation">(Mood <a href="#ref-mood" role="doc-biblioref">2010</a>; Ranganathan, Pramesh, and Aggarwal <a href="#ref-pitfalls" role="doc-biblioref">2017</a>)</span>, which is arguably the simplest way to implement classification.</p>
<p>Classical applications of Bayesian statistics (Figure <a href="intro.html#fig:data-vs-modeller">1.1</a>, top right) address some of these
limitations. The modeller still has to structure a model covering both the data and any prior beliefs on their
behaviour, but the posterior may be estimated algorithmically using Markov Chain Monte Carlo (MCMC).</p>
<p>In contrast <span class="citation">(Breiman <a href="#ref-two-cultures" role="doc-biblioref">2001</a><a href="#ref-two-cultures" role="doc-biblioref">b</a>)</span>, algorithmic approaches shift the burden from the modeller to data collection and computer
software (Figure <a href="intro.html#fig:data-vs-modeller">1.1</a>, top left). The modeller’s role in constructing the probabilistic model is
limited, and is largely replaced by a computer system sifting through large amounts of data: hence the name “machine
learning”. The structure of the model is learned from the data, with few limitations in what it may look like. Neural
networks and Gaussian processes are universal approximators, for instance. Almost all the information comes from the
data, instead of being prior information that is mediated by the modeller, which is why machine learning approaches are
data-hungry.</p>
</div>
<div id="intro-ds" class="section level2 hasAnchor" number="1.2">
<h2><span class="header-section-number">1.2</span> Data Science<a href="intro.html#intro-ds" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Data science is similarly data-driven (Figure <a href="intro.html#fig:data-vs-modeller">1.1</a>, top left), but focuses on extracting insights
from raw data and presenting them graphically to support principled decision making. Kenett and Redman <span class="citation">(Kenett and Redman <a href="#ref-kenett" role="doc-biblioref">2019</a>)</span>
describe it as follows: “the real work of data scientists involves helping people make better decisions on the important
issues in the near term and building stronger organizations in the long term”. It requires strong involvement from the
data scientist in all areas of business, shifting the focus from computer systems to people. Nevertheless, data
scientists use statistical and machine learning models as the means to obtain those insights.</p>
<p>Compared to classical statistics, when data are abundant (Big Data! <span class="citation">(Katal, Wazid, and Goudar <a href="#ref-bigdata" role="doc-biblioref">2013</a>)</span>) we do not really need to construct their
generating process from prior knowledge. The data contain enough information for us to “let them speak for themselves”
and obtain useful insights, which are what we are mainly interested in. Of course, prior information from experts is
still useful: models that incorporate it tend to be better at producing insights that can be acted upon.</p>
<p>As a result, data science puts a strong focus on the quality of the data, which is often problematic when dealing with
data aggregated from multiple sources (data fusion) or with non-tabular data (natural language processing and computer
vision). Often, data are poorly defined, simply wrong or ultimately irrelevant for the purpose they were collected for.
Expert knowledge is crucial to assess them, to integrate them and to fix them if possible. Machine learning is widely
applied to both text and images as well, but focused mostly on modelling their hidden structure until recently, when
explainability became a hot topic <span class="citation">(see, for instance, Li et al. <a href="#ref-nlp-viz" role="doc-biblioref">2016</a>; Simonyan, Vedaldi, and Zisserman <a href="#ref-cv-viz" role="doc-biblioref">2014</a>)</span>.</p>
<p>Computer systems are key to data science, albeit with a different role than in machine learning. Storing and accessing
large amounts of data, exploring them interactively, building the software pipelines that analyse them, handling the
resulting spiky workloads: these are all tasks that require a sophisticated use of both hardware and software.</p>
</div>
<div id="intro-sweng" class="section level2 hasAnchor" number="1.3">
<h2><span class="header-section-number">1.3</span> Software Engineering<a href="intro.html#intro-sweng" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Software engineering is the systematic application of sound engineering principles to all phases of the software life
cycle: design, development, maintenance, testing and evaluation <span class="citation">(van Vliet <a href="#ref-vanvliet" role="doc-biblioref">2008</a>)</span>. Its central tenet is mastering the
complexity inherent to developing large pieces of software that are reliable and efficient; that are usable and can be
evolved over time; and that can be developed and maintained in a viable way in terms of both cost and effort <span class="citation">(Ousterhout <a href="#ref-philo" role="doc-biblioref">2018</a>)</span>.</p>
<p>Early definitions of software engineering suggested that we should treat it as if it were a traditional engineering
discipline like, say, civil engineering. The result is the <em>waterfall model</em> <span class="citation">(Royce <a href="#ref-waterfall" role="doc-biblioref">1987</a>)</span>, which lays out software
development as a sequence of steps starting from collecting requirements and finishing with the deployment of the
finished product. Modern practices recognise, however, that this model is flawed in several ways. Firstly, civil
engineering arises from and is bound by the laws of physics, whereas we make up our own world with its own rules when we
develop software. These rules will change over time as our understanding of the problem space evolves; the laws of
physics do not. Secondly, the task the software is meant to perform will change over time, and our working definition of
that task will change as well. Civil engineering mostly deals with well-defined problems that stay well-defined for the
duration of the project. Finally, modifying a large building after its construction is completed is very difficult,
but we routinely do that with software. Most of the overall effort in the software lifetime is usually in maintaining
and evolving it.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:software-life-cycle"></span>
<img src="chapter01/figures/software-life-cycle.svg" alt="A schematic view of the phases of the software development life-cycle." width="80%" />
<p class="caption">
Figure 1.2: A schematic view of the phases of the software development life-cycle.
</p>
</div>
<p>Current software engineering practices take the opposite view that software development is an open-ended (“software is
never done”), iterative (the “software life-cycle”) process: this is the core of the “Agile Manifesto” <span class="citation">(Beck et al. <a href="#ref-agile" role="doc-biblioref">2001</a>)</span>. At a
high level, it is organised as shown in Figure <a href="intro.html#fig:software-life-cycle">1.2</a>: a perpetual cycle of planning, analysis,
design, implementation, testing and maintenance. The design of the software is heavily influenced by the domain it
operates in <span class="citation">(domain-driven development, Evans <a href="#ref-domain-driven" role="doc-biblioref">2003</a>)</span>. It uses tests <span class="citation">(test-driven development, Beck <a href="#ref-tdd" role="doc-biblioref">2002</a>)</span>, refactoring
<span class="citation">(Fowler <a href="#ref-refactoring" role="doc-biblioref">2018</a>)</span> and continuous integration <span class="citation">(Duvall, Matyas, and Glover <a href="#ref-cicd" role="doc-biblioref">2007</a>)</span> to incorporate new features, to fix bugs in a timely manner and to
keep the code “in shape”. Admittedly, all of these approaches have been touted as silver bullets to the point they have
become buzzwords, and their practical implementation has often distorted them to the point of making software
development worse. However, the key ideas of agile have merit, and we will discuss and apply them in moderation in this
book. They are well suited to structure the development of machine learning pipelines, which are built on a combination
of mutable models and input data.</p>
</div>
<div id="intro-together" class="section level2 hasAnchor" number="1.4">
<h2><span class="header-section-number">1.4</span> How Do They Go Together?<a href="intro.html#intro-together" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The centrality of computing in machine learning and data science makes software engineering practices essential in
modern data analysis: most of the work is done by computer systems, which are powered by software.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> Encoding the data, storing and retrieving them efficiently, implementing machine learning models,
tying them together and with other systems: each of these tasks is complex enough that only sound engineering practices
can ensure the overall correctness of what we are doing. This is true, in different ways, for both academic research and
industry applications. As Kenett and Redman <span class="citation">(Kenett and Redman <a href="#ref-kenett" role="doc-biblioref">2019</a>)</span> put it, using a car analogy:</p>
<blockquote>
<p>“If data is the new oil, technology is the new engine. The engine powers the car and, without technological
advancements, a data- and analytics-led transformation would not be possible. Technologies include databases,
communications systems and protocols, applications that support the storage and processing of data, and the raw
computing horsepower (much of it now in the cloud) to drive it all.”</p>
</blockquote>
<p>In academia, there is a widespread belief that the software implementations of novel methods can be treated as “one-off
scripts”. “We only need to run it once to write this paper, there is no point in refactoring and re-engineering it.” is
a depressingly common sentiment. As is not sharing code to “stay ahead of the competition”. However, research and
application papers using machine learning rely crucially on the quality of the software they use because:</p>
<ol style="list-style-type: decimal">
<li>The models themselves are often black boxes whose mathematical behaviour is not completely understood (Section
<a href="troubleshooting-code.html#model-problems">9.2</a>).</li>
<li>The data are complex enough that even experts in the domains they come from struggle to completely explain them
(Section <a href="troubleshooting-code.html#data-problems">9.1</a>).</li>
</ol>
<p>If we do not understand both the data and the models completely, it becomes very difficult to spot problems in the
software we use to work on them: unexpected behaviour arising from software bugs may be mistaken for a peculiarity in
either of them. It is then crucial that we minimise the chances of this happening by applying all the best engineering
practices we have at our disposal. Present and past failures to do so have led to a widespread “reproducibility crisis”
in fields as diverse as drug research <span class="citation">(Prinz, Schlange, and Asadullah <a href="#ref-repro3" role="doc-biblioref">2011</a>, 20–25% reproducible)</span>, comparative psychology <span class="citation">(Stevens <a href="#ref-repro4" role="doc-biblioref">2017</a>, 36%
reproducible)</span>, finance <span class="citation">(Chang and Li <a href="#ref-repro5" role="doc-biblioref">2015</a>, 43% reproducible)</span> and computational neuroscience <span class="citation">(Miłkowski, Hensel, and Hohol <a href="#ref-repro6" role="doc-biblioref">2018</a>, only 12% of papers provide
both data and code)</span>. Machine learning and artificial intelligence research is in a similarly sorry state: that “when the
original authors provided assistance to the reproducers, 85% of results were successfully reproduced, compared to 4%
when the authors didn’t respond” <span class="citation">(Pineau et al. <a href="#ref-repro7" role="doc-biblioref">2021</a>)</span> <em>does</em> suggest that there is margin for improvement. Fortunately, in recent
years scientists have widely accepted this is a problem <span class="citation">(Nature <a href="#ref-repro1" role="doc-biblioref">2016</a>)</span>, and the machine learning community has reached some
consensus on how to tackle it <span class="citation">(Tatman, VanderPlas, and Dane <a href="#ref-repro2" role="doc-biblioref">2018</a>)</span>.</p>
<p>In industry, poor engineering leads to lower practical and computational performance and a quick accumulation of
technical debt <span class="citation">(Sculley et al. <a href="#ref-hidden-debt" role="doc-biblioref">2015</a>, and Section <a href="design-code.html#technical-debt">5.2</a>)</span>. Badly engineered data may not contain the information
we are looking for in a usable form; models that are not well packaged may be slow to deploy and difficult to roll back;
data may contain biases or may change over time in ways that make models fail silently; or the machine learning software
may become an inscrutable black box whose outputs are impossible to explain, making troubleshooting impossible.</p>
<p>To conclude, we believe that solid machine learning applications and research rest on three pillars:</p>
<ol style="list-style-type: decimal">
<li>The foundations of machine learning (mathematics, probability, computer science), which provide guarantees that the
models work.</li>
<li>Software engineering, which provides guarantees that the implementations of the models work (effectively and
efficiently).</li>
<li>The quality of the data in terms of features, size, fairness, and in how they were collected.</li>
</ol>
<p>In this book, we will concentrate on the software engineering aspect, touching briefly on some aspects of the data. We
will not discuss the theoretical or methodological aspects of machine learning, which are better covered in the huge
amount of specialised literature published to date <span class="citation">(such as Hastie, Tibshirani, and Friedman <a href="#ref-elemstatlearn" role="doc-biblioref">2009</a>; Russell and Norvig <a href="#ref-norvig" role="doc-biblioref">2009</a>; Goodfellow, Bengio, and Courville <a href="#ref-goodfellow" role="doc-biblioref">2016</a>; Gelman et al. <a href="#ref-gelman" role="doc-biblioref">2013</a>; Rasmussen and Williams <a href="#ref-gaussianproc" role="doc-biblioref">2006</a> and
many others)</span>.</p>
<!-- vim: set synmaxcol=600 textwidth=120 colorcolumn=120 spell wrap number: -->

</div>
</div>



</div>
<h3>References</h3>
<div id="refs" class="references hanging-indent">
<div id="ref-mlfortext">
<p>Aggarwal, C. C. 2018. <em>Machine Learning for Text</em>. Springer.</p>
</div>
<div id="ref-tdd">
<p>Beck, K. 2002. <em>Test-Driven Development by Example</em>. Addison-Wesley.</p>
</div>
<div id="ref-agile">
<p>Beck, K., M. Beedle, A. Van Bennekum, A. Cockburn, W. Cunningham, M. Fowler, J. Grenning, et al. 2001. <em>The Agile Manifesto</em>. <a href="https://www.agilealliance.org/wp-content/uploads/2019/09/agile-manifesto-download-2019.pdf">https://www.agilealliance.org/wp-content/uploads/2019/09/agile-manifesto-download-2019.pdf</a>.</p>
</div>
<div id="ref-two-cultures">
<p>Breiman, L. 2001b. “Statistical Modeling: The Two Cultures.” <em>Statistical Science</em> 16 (3): 199–231.</p>
</div>
<div id="ref-google-tpu">
<p>Cass, S. 2019. “Taking AI to the Edge: Google’s TPU Now Comes in a Maker-Friendly Package.” <em>IEEE Spectrum</em> 56 (5): 16–17.</p>
</div>
<div id="ref-castillo">
<p>Castillo, E., J. M. Gutiérrez, and A. S. Hadi. 1997. <em>Expert Systems and Probabilistic Network Models</em>. Springer.</p>
</div>
<div id="ref-repro5">
<p>Chang, A. C., and P. Li. 2015. “Is Economics Research Replicable? Sixty Published Papers from Thirteen Journals Say ‘Usually Not’.” In <em>Federal Reserve Board Finance and Economics Discussion Paper</em>, 083.</p>
</div>
<div id="ref-cicd">
<p>Duvall, P. M., S. Matyas, and A. Glover. 2007. <em>Continuous Integration: Improving Software Quality and Reducing Risk</em>. Addison-Wesley.</p>
</div>
<div id="ref-domain-driven">
<p>Evans, E. 2003. <em>Domain-Driven Design: Tackling Complexity in the Heart of Software</em>. Addison-Wesley.</p>
</div>
<div id="ref-refactoring">
<p>Fowler, M. 2018. <em>Refactoring: Improving the Design of Existing Code</em>. 2nd ed. Addison-Wesley.</p>
</div>
<div id="ref-gelman">
<p>Gelman, A., B. Carlin, H. S. Stern, D. B. Dunson, and A. Vehtari. 2013. <em>Bayesian Data Analysis</em>. 3rd ed. CRC Press.</p>
</div>
<div id="ref-zoubin">
<p>Ghahramani, Z. 2015. “Probabilistic Machine Learning and Artificial Intelligence.” <em>Nature</em> 521: 452–59.</p>
</div>
<div id="ref-goodfellow">
<p>Goodfellow, I., Y. Bengio, and A. Courville. 2016. <em>Deep Learning</em>. MIT Press.</p>
</div>
<div id="ref-elemstatlearn">
<p>Hastie, T., R. Tibshirani, and J. Friedman. 2009. <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</em>. 2nd ed. Springer.</p>
</div>
<div id="ref-bigdata">
<p>Katal, A., M. Wazid, and R. H. Goudar. 2013. “Big Data: Issues, Challenges, Tools and Good Practices.” In <em>Proceedings of the International Conference on Contemporary Computing</em>, 404–9.</p>
</div>
<div id="ref-kenett">
<p>Kenett, R. S., and T. C. Redman. 2019. <em>The Real Work of Data Science</em>. Wiley.</p>
</div>
<div id="ref-nlp-viz">
<p>Li, J., X. Chen, E. Hovy, and D. Jurafsky. 2016. “Visualizing and Understanding Neural Models in NLP.” In <em>Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</em>, 681–91. Association for Computational Linguistics.</p>
</div>
<div id="ref-repro6">
<p>Miłkowski, M., W. M. Hensel, and M. Hohol. 2018. “Replicability or Reproducibility? On the Replication Crisis in Computational Neuroscience and Sharing Only Relevant Detail.” <em>Journal of Computational Neuroscience</em> 45: 163–72.</p>
</div>
<div id="ref-mood">
<p>Mood, C. 2010. “Logistic Regression: Why We Cannot Do What We Think We Can Do, and What We Can Do About It.” <em>European Sociological Review</em> 26 (1): 67–82.</p>
</div>
<div id="ref-repro1">
<p>Nature. 2016. “Reality Check on Reproducibility.” <em>Nature</em> 533 (437).</p>
</div>
<div id="ref-cuda">
<p>Nvidia. 2021. <em>CUDA Toolkit Documentation</em>. <a href="https://docs.nvidia.com/cuda/">https://docs.nvidia.com/cuda/</a>.</p>
</div>
<div id="ref-philo">
<p>Ousterhout, J. 2018. <em>A Philosophy of Software Design</em>. Yaknyam Press.</p>
</div>
<div id="ref-repro7">
<p>Pineau, J., P. Vincent-Lamarre, K. Sinha, V. Larivière, A. Beygelzimer, F. d’Alché-Buc, E. Fox, and H. Larochelle. 2021. “Improving Reproducibility in Machine Learning Research (A Report from the NeurIPS 2019 Reproducibility Program).” <em>Journal of Machine Learning Research</em> 22: 1–20.</p>
</div>
<div id="ref-repro3">
<p>Prinz, F., T. Schlange, and K. Asadullah. 2011. “Believe It or Not: How Much Can We Rely on Published Data on Potential Drug Targets?” <em>Nature Reviews Drug Discovery</em> 10: 712.</p>
</div>
<div id="ref-pitfalls">
<p>Ranganathan, P., C. S. Pramesh, and R. Aggarwal. 2017. “Common Pitfalls in Statistical Analysis: Logistic Regression.” <em>Perspectives in Clinical Research</em> 8 (3): 148–51.</p>
</div>
<div id="ref-gaussianproc">
<p>Rasmussen, C. E., and C. K. I. Williams. 2006. <em>Gaussian Processes for Machine Learning</em>. MIT Press.</p>
</div>
<div id="ref-ai-accelerators">
<p>Reuther, A., P. Michaleas, M. Jones, V. Gadepally, S. Samsi, and J. Kepner. 2020. “Survey of Machine Learning Accelerators.” In <em>Proceedings of the 2020 Ieee High Performance Extreme Computing Conference (Hpec)</em>, 1–12.</p>
</div>
<div id="ref-waterfall">
<p>Royce, W. W. 1987. “Managing the Development of Large Software Systems: Concepts and Techniques.” In <em>Proceedings of the 9th International Conference on Software Engineering</em>, 328–38.</p>
</div>
<div id="ref-norvig">
<p>Russell, S. J., and P. Norvig. 2009. <em>Artificial Intelligence: A Modern Approach</em>. 3rd ed. Prentice Hall.</p>
</div>
<div id="ref-hidden-debt">
<p>Sculley, D., G. Holt, D. Golovin, E. Davydov, T. Phillips, D. Ebner, V. Chaudhary, M. Young, J.-F. Crespo, and D. Dennison. 2015. “Hidden Technical Debt in Machine Learning Systems.” In <em>Proceedings of the 28th International Conference on Neural Information Processing Systems (NIPS)</em>, 2:2503–11.</p>
</div>
<div id="ref-scutari">
<p>Scutari, M., and J.-B. Denis. 2021. <em>Bayesian Networks with Examples in R</em>. 2nd ed. Chapman &amp; Hall.</p>
</div>
<div id="ref-cv-viz">
<p>Simonyan, K., A. Vedaldi, and A. Zisserman. 2014. “Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps.” In <em>Proceedings of the 2nd International Conference on Learning Representations (ICLR), Workshop Track</em>.</p>
</div>
<div id="ref-repro4">
<p>Stevens, J. R. 2017. “Replicability and Reproducibility in Comparative Psychology.” <em>Frontiers in Psychology</em> 8: 862.</p>
</div>
<div id="ref-repro2">
<p>Tatman, R., J. VanderPlas, and S. Dane. 2018. “A Practical Taxonomy of Reproducibility for Machine Learning Research.” In <em>Proceedings of 2nd the Reproducibility in Machine Learning Workshop at ICML 2018</em>.</p>
</div>
<div id="ref-mihaela">
<p>van der Schaar, M., A. M. Alaa, A. Floto, A. Gimson, S. Scholtes, A. Wood, E. McKinney, D. Jarrett, P. Liò, and A. Ercole. 2021. “How Artificial Intelligence and Machine Learning Can Help Healthcare Systems Respond to COVID-19.” <em>Machine Learning</em> 110: 1–14.</p>
</div>
<div id="ref-vanvliet">
<p>van Vliet, H. 2008. <em>Software Engineering: Principles and Practice</em>. Wiley.</p>
</div>
<div id="ref-vision">
<p>Voulodimos, A., N. Doulamis, A. Doulamis, and E. Protopapadakis. 2018. “Deep Learning for Computer Vision: A Brief Review.” <em>Computational Intelligence and Neuroscience</em> 2018 (7068349): 1–13.</p>
</div>
<div id="ref-weisberg">
<p>Weisberg, S. 2014. <em>Applied Linear Regression</em>. 4th ed. Wiley.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>This is not to
discount the role of hardware, just to set the focus of the book. Processing units tailored to machine learning use are
an active research and engineering field as exemplified by Nvidia <span class="citation">(Nvidia <a href="#ref-cuda" role="doc-biblioref">2021</a>)</span>, Google <span class="citation">(Cass <a href="#ref-google-tpu" role="doc-biblioref">2019</a>)</span> and other companies
<span class="citation">(Reuther et al. <a href="#ref-ai-accelerators" role="doc-biblioref">2020</a>)</span>.<a href="intro.html#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="hardware.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
